#!/bin/bash
#
# DataBridge Server Synchronization Script for simple projects
# Copyright (C) 2014-2015  Ioannis Charalampidis, PH-SFT, CERN

# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#

# Base directory for the DataBridge
DB_URL="https://t4t-data-bridge.cern.ch"

# We will need the BOINC UserID and BOINC Authenticator as the first two parameters
AUTH_USER="$1"
AUTH_PASSWORD="$2"
[ -z "$AUTH_USER" ] && echo "ERROR: Please specify the authentication username!" && exit 2
[ -z "$AUTH_PASSWORD" ] && echo "ERROR: Please specify the authentication password!" && exit 2
[ ! -z "$3" ] && DB_URL="$3"

# Define URLs using base URL as reference
DB_QUEUE_URL="${DB_URL}/boinc-client/get-job.cgi"
DB_INPUT_URL="${DB_URL}/myfed/t4t-boinc/input"
DB_OUTPUT_URL="${DB_URL}/myfed/t4t-boinc/output"

function get_jobfile {
    local JOBDIR=$1

    # Get a job ID from the queue
    local NEXT_JOB_ID=$(curl -f -u "${AUTH_USER}:${AUTH_PASSWORD}" --header "userID: ${AUTH_USER}" -k -s "${DB_QUEUE_URL}" 2>/dev/null)

    # If we got an error, return
    if [ $? -ne 0 ]; then
        echo "ERROR: Could not fetch next job ID from queue"
        return 1
    fi

    # If queue is empty, return
    [ -z "$NEXT_JOB_ID" ] && return 1

    # Download job file
    local JOB_FILE="${JOBDIR}/job.sh"
    curl -f -o ${JOB_FILE} -u "${AUTH_USER}:${AUTH_PASSWORD}" -k -L -s "${DB_INPUT_URL}/${NEXT_JOB_ID}" 2>/dev/null

    # If we got an error, return
    if [ $? -ne 0 ]; then
        echo "ERROR: Could not download job contents from server"
        return 1
    fi

    # Got file
    JOB_ID="$NEXT_JOB_ID"
    return 0
}

function upload_jobdir {
    local JOBDIR=$1
    local JOB_ID=$2
    local USER_DATA=$3

    # Archive job directory
    local ARCHIVE_FILE="$(mktemp -u).tgz"
    ( cd ${JOBDIR}; tar -zcf ${ARCHIVE_FILE} ./* )

    # Upload archive directory
    curl -X PUT --upload "${ARCHIVE_FILE}" -u "${AUTH_USER}:${AUTH_PASSWORD}" -k -L -s "${DB_OUTPUT_URL}/${JOB_ID}.tgz?userdata=${USER_DATA}" 2>/dev/null

    # Remove archive file
    rm "${ARCHIVE_FILE}"
}

function cleanup {
    # Remove directory
    [ -d ${WORKDIR} -a ${#WORKDIR} -gt 1 ] && rm -rf ${WORKDIR}
    # Exit
    exit 0
}

# Trap cleanup
trap cleanup SIGINT

# Main program loop
while true; do

    # Create a temporary directory for the project
    WORKDIR=$(mktemp -d)

    # Download job file
    JOB_ID=""
    while [ -z "$JOB_ID" ]; do

        # Log attempts
        echo "INFO: Fetching next job in queue"

        # Get next job file (updates JOB_ID)
        get_jobfile "${WORKDIR}"

        # Sleep on errors
        if [ $? -ne 0 ]; then
            echo "INFO: Sleeping for 1 minute"
            sleep 60
        fi

    done

    # Run job
    echo "INFO: Starting job ${JOB_ID}"
    ( cd "${WORKDIR}"; chmod +x job.sh; exec ./job.sh ) >${WORKDIR}/job.stdout 2>${WORKDIR}/job.stderr

    # Get exit code
    EXIT_CODE=$?

    # Upload results
    echo "INFO: Uploading results"
    upload_jobdir "${WORKDIR}" "${JOB_ID}" "exitcode=$EXIT_CODE&vmid=${DUMBQ_VMID}"

    # Cleanup
    echo "INFO: Cleaning-up workdir"
    rm -rf "${WORKDIR}"

    # Sleep a bit
    sleep 10

done
